**Q594**

회사는 AWS 로 마이그레이션하고 애플리케이션에 Amazon EC2 온디맨드 인스턴스를
사용할 계획입니다. 마이그레이션 테스트 단계에서 기술 팀은 애플리케이션이 완전히
생산되기 위해 메모리를 실행하고 로드하는 데 오랜 시간이 걸린다는 사실을 관찰했습니다.
다음 테스트 단계에서 애플리케이션 실행 시간을 단축할 솔루션은 무엇입니까?

A. 두 개 이상의 EC2 온디맨드 인스턴스를 시작합니다. Auto Scaling 기능을 활성화하고
다음 테스트 단계에서 EC2 온디맨드 인스턴스를 사용할 수 있도록 하십시오.
B. EC2 스팟 인스턴스를 시작하여 애플리케이션을 지원하고 다음 테스트 단계에서 사용할
수 있도록 애플리케이션을 확장합니다.
C. 최대 절전 모드를 활성화한 상태에서 EC2 온디맨드 인스턴스를 시작합니다. 다음
테스트 단계에서 EC2 Auto Scaling 웜 풀을 구성합니다.
D. 용량 예약을 통해 EC2 온디맨드 인스턴스를 시작합니다. 다음 테스트 단계에서 추가
EC2 인스턴스를 시작하십시오.

내가 생각한 답 : 

C → 절전 모드는 중지시 RAM 내용을 EBS에 저장하고 시작 시 RAM을 복원하여 프로세스를 이어서 실행한다. 이를 사용하면 실행 시간을 단축할 수 있을거라고 생각했다.

해설 : 

- **Hibernate(최대 절전 모드)** :
    - 한 번 애플리케이션을 다 띄워놓고 → RAM 상태를 EBS에 저장 → 인스턴스를 중지
    - 다음에 시작할 때는 **부팅 → 애플리케이션 cold start**가 아니라
        
        **RAM 상태 복구 = 애플리케이션이 이미 떠 있는 상태에서 재개**
        

> EC2 인스턴스 기동 + 애플리케이션 로딩이 너무 느림
> 
> 
> → 미리 띄워놓고 절전했다가 다시 켜야함
> 
- 여기에 **ASG 웜 풀(warm pool)** 을 같이 쓰면:
    - 미리 hibernate 상태의 인스턴스를 풀에 넣어 두고
    - 필요 시 빠르게 꺼내서 Running 시킴 → 테스트 단계 시작 시간을 크게 단축

**Q595**

회사의 애플리케이션은 Auto Scaling 그룹의 Amazon EC2 인스턴스에서 실행됩니다.
회사는 해당 애플리케이션이 일주일 중 임의의 요일에 갑작스러운 트래픽 증가를
경험한다는 사실을 발견했습니다. 회사는 갑작스러운 트래픽 증가 중에도 애플리케이션
성능을 유지하려고 합니다.
이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?

A. Auto Scaling 그룹의 크기를 변경하려면 수동 스케일링을 사용하십시오.
B. 예측 조정을 사용하여 Auto Scaling 그룹의 크기를 변경합니다.
C. 동적 스케일링을 사용하여 Auto Scaling 그룹의 크기를 변경합니다.
D. 일정 조정을 사용하여 Auto Scaling 그룹의 크기를 변경합니다.

내가 생각한 답 : 

C → 일주일 중 임의(중요!!!)의 요일에 갑작스러운 트래픽 증가에 대응하는 것이므로 동적 스케일링을 사용해서 Auto Scaling 그룹의 크기를 변경하는게 적합하다고 생각했다.

해설 : 

예측 불가능한 타이밍 → **예약 스케줄링으로는 대응 불가**

갑자기 튀는 부하에 **실시간 반응 + 부하 없을 때는 축소** → 비용 절감까지 달성

→ 동적 스케일링이 적합

**Q566**

회사는 2 개의 가용 영역에 걸쳐 VPC 에서 여러 Amazon EC2 Linux 인스턴스를 실행합니다.
인스턴스는 계층적 디렉터리 구조를 사용하는 애플리케이션을 호스팅합니다.
애플리케이션은 공유 스토리지에서 동시에 빠르게 읽고 쓸 수 있어야 합니다.
솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. Amazon S3 버킷을 생성합니다. VPC 의 모든 EC2 인스턴스에서 액세스를 허용합니다.
B. Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. 각 EC2
인스턴스에서 EFS 파일 시스템을 탑재합니다.
C. 프로비저닝된 IOPS SSD(io2) Amazon Elastic Block Store(Amazon EBS) 볼륨에 파일
시스템을 생성합니다. EBS 볼륨을 모든 EC2 인스턴스에 연결합니다.
D. 각 EC2 인스턴스에 연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨에 파일
시스템을 만듭니다. 여러 EC2 인스턴스 간에 EBS 볼륨을 동기화합니다.

내가 생각한 & 찾아본 답 : 

A 아니면… B → C,D는 EBS는 느려서 제외하고 A,B 중에 골랐다…

EFS를 찾아보니 “스토리지 용량과 성능을 프로비저닝하거나 관리할 필요 없이 사용량에 따라 자동으로 확장됩니다” 라고 한다.

A : S3는 **지연 시간이 크고** 파일시스템 수준 락/동시성 보장도 애매하다 → X

C : 기본적으로 한 볼륨은 한 EC2 인스턴스에만 연결 가능 → X

D : 동기화는 에러가 생길 가능성도 높고 복잡하다 → X

B는 

- “2개의 가용영역(AZ)에 걸친 VPC” → EFS는 **Multi-AZ 지원**
- “계층적 디렉터리 구조” → 파일시스템 그대로
- “공유 스토리지에서 동시에 빠르게 읽고 쓸 수 있어야 함” → EFS가 완전 적합하다.
